{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Users/Lenovo/Downloads/glass.csv\")\n",
    "\n",
    "## 1. Data Exploration\n",
    "print(\"Data Exploration\")\n",
    "print(\"\\nDataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "print(\"\\nData types:\\n\", data.dtypes)\n",
    "print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
    "print(\"\\nClass distribution:\\n\", data['type'].value_counts())\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "data = data.drop_duplicates()\n",
    "print(\"\\nShape after removing duplicates:\", data.shape)\n",
    "\n",
    "X = data.iloc[:, 1:-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Split data (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ],
   "id": "bc46184f637c360",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# a. Univariate selection\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "fit = bestfeatures.fit(X, y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Feature', 'Score']\n",
    "print(\"\\nTop 5 features using Univariate Selection:\")\n",
    "top5_uni = featureScores.nlargest(5, 'Score')\n",
    "print(top5_uni)"
   ],
   "id": "e747a6c8d8f4d021",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# b. Feature importance\n",
    "model = ExtraTreesClassifier(random_state=10)\n",
    "model.fit(X, y)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top5_imp = feat_importances.nlargest(5)\n",
    "print(\"\\nTop 5 features using Feature Importance:\")\n",
    "print(top5_imp)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10,6))\n",
    "feat_importances.nlargest(5).plot(kind='barh')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.show()"
   ],
   "id": "b7d3efa43874ade3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# c. Correlation\n",
    "corr_data = pd.concat([X, y], axis=1)\n",
    "corrmat = corr_data.corr()\n",
    "top_corr = corrmat['type'].abs().sort_values(ascending=False).head(6)\n",
    "top_corr = top_corr.drop('type')\n",
    "top5_corr = pd.DataFrame({'Feature': top_corr.index, 'Correlation': top_corr.values})\n",
    "print(\"\\nTop 5 features using Correlation:\")\n",
    "print(top5_corr)\n",
    "\n",
    "# Plot correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"RdYlGn\", fmt='.2f')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ],
   "id": "c7fa7827d430d22d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Model development and evaluation\n",
    "def evaluate_model(X, y, features_used=\"All features\"):\n",
    "    print(f\"\\nEvaluating model with {features_used}:\")\n",
    "\n",
    "    # Create and train model\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 8-fold cross validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=8)\n",
    "    print(f\"\\n8-fold CV Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
   ],
   "id": "b100480b498c0a9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate with all features\n",
    "evaluate_model(X, y)\n",
    "\n",
    "# Evaluate with top 5 features from univariate selecyion\n",
    "X_uni = X[top5_uni['Feature'].values]\n",
    "evaluate_model(X_uni, y, \"Top 5 Univariate features\")\n",
    "\n",
    "# Evaluate with top 5 features from Importance Features\n",
    "X_imp = X[top5_imp.index]\n",
    "evaluate_model(X_imp, y, \"Top 5 Feature Importance features\")\n",
    "\n",
    "# Evaluate with top 5 features from Correlation\n",
    "X_corr = X[top5_corr['Feature'].values]\n",
    "evaluate_model(X_corr, y, \"Top 5 Correlation features\")"
   ],
   "id": "f295092d3a888f91",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
