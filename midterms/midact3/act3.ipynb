{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/Lenovo/Downloads/heart_disease_prediction.csv\")\n",
    "\n",
    "# Data Exploration\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nNumber of duplicates before removal:\", df.duplicated().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Handle missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].median(), inplace=True)"
   ],
   "id": "7cff38c7dfa3aa03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for outliers using IQR\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()\n",
    "print(\"\\nOutliers detected:\\n\", outliers)"
   ],
   "id": "6ca986e603596f30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove outliers using IQR\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Identify numerical columns for outlier removal\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if 'tenYearCHD' in numerical_cols:\n",
    "    numerical_cols.remove('tenYearCHD')  # Don't remove outliers from target variable\n",
    "\n",
    "original_size = df.shape[0]\n",
    "df = remove_outliers(df, numerical_cols)\n",
    "print(f\"Removed {original_size - df.shape[0]} outliers ({((original_size - df.shape[0])/original_size)*100:.2f}% of data)\")\n",
    "print(\"Dataset shape after outlier removal:\", df.shape)"
   ],
   "id": "6390153faa52d781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature selection based on p-values\n",
    "X = df.drop('tenYearCHD', axis=1)\n",
    "y = df['tenYearCHD']\n",
    "\n",
    "# Select top 10 features based on ANOVA F-value\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "selector.fit(X, y)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(\"\\nTop 10 features based on p-values:\\n\", selected_features)\n",
    "\n",
    "# Update dataframe with selected features\n",
    "df_selected = df[list(selected_features) + ['tenYearCHD']]"
   ],
   "id": "786296428ff542fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Check class imbalance\n",
    "print(\"\\nClass distribution:\\n\", df_selected['tenYearCHD'].value_counts())\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "X = df_selected.drop('tenYearCHD', axis=1)\n",
    "y = df_selected['tenYearCHD']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "print(\"\\nClass distribution after SMOTE:\\n\", y_res.value_counts())"
   ],
   "id": "2949d0513c33be65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Splitting\n",
    "# First split: 10% for final unseen test, 90% for model development\n",
    "X_dev, X_unseen, y_dev, y_unseen = train_test_split(X_res, y_res, test_size=0.1, random_state=42, stratify=y_res)\n",
    "\n",
    "# Second split: 80% training, 20% testing from the development set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.2, random_state=42, stratify=y_dev)"
   ],
   "id": "3324a94f7722febe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_unseen_scaled = scaler.transform(X_unseen)"
   ],
   "id": "9f425b5e70f107e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nModel Evaluation on Test Set:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.show()\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Data Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Test Data Precision: {precision:.2f}\")\n",
    "print(f\"Test Data Recall: {recall:.2f}\")\n",
    "print(f\"Test Data F1 Score: {f1:.2f}\")"
   ],
   "id": "925330dbf216c85a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefficients)\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ],
   "id": "7f1e9c3daaa7720d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Predict on unseen data\n",
    "y_unseen_pred = lr.predict(X_unseen_scaled)\n",
    "\n",
    "# Evaluate on unseen data\n",
    "print(\"\\nUnseen Data Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_unseen, y_unseen_pred))\n",
    "cm = confusion_matrix(y_unseen, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Unseen Data)')\n",
    "plt.show()\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_unseen, y_unseen_pred))\n",
    "\n",
    "unseen_accuracy = accuracy_score(y_unseen, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen, y_unseen_pred)\n",
    "unseen_recall = recall_score(y_unseen, y_unseen_pred)\n",
    "unseen_f1 = f1_score(y_unseen, y_unseen_pred)\n",
    "\n",
    "print(f\"Unseen Data Accuracy: {unseen_accuracy:.2f}\")\n",
    "print(f\"Unseen Data Precision: {unseen_precision:.2f}\")\n",
    "print(f\"Unseen Data Recall: {unseen_recall:.2f}\")\n",
    "print(f\"Unseen Data F1 Score: {unseen_f1:.2f}\")"
   ],
   "id": "3d0f83dba8e3b944"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
